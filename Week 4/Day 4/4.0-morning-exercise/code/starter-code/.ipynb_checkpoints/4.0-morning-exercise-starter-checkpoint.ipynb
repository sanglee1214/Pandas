{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige\n",
      "0      0  380.0  3.61       3.0\n",
      "1      1  660.0  3.67       3.0\n",
      "2      1  800.0  4.00       1.0\n",
      "3      1  640.0  3.19       4.0\n",
      "4      0  520.0  2.93       4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SangYeob/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:20: FutureWarning: using '+' to provide set union with Indexes is deprecated, use '|' or .union()\n"
     ]
    }
   ],
   "source": [
    "# This dataset you have seen, but this time we will properly split the data from the actual\n",
    "# dataset into two, and fit the model on the train dataset, and test on the test dataset.\n",
    "# Then we will iterate through class thresholds, to see which threshold gives the best confusion\n",
    "# matrix. The first steps have been done for you \n",
    "# (creating dummies, joining to df, creating y series and features only dataframe \n",
    "# but please be familiar with these first steps! \n",
    "\n",
    "df_raw = pd.read_csv(\"../../assets/admissions.csv\")\n",
    "df = df_raw.dropna() \n",
    "\n",
    "dummies = pd.get_dummies( df[\"prestige\"], prefix = \"prestige\" )\n",
    "\n",
    "print df.head()\n",
    "\n",
    "join = df[ df.columns[0:3] ].join(dummies)\n",
    "join[\"intercept\"] = 1\n",
    "\n",
    "joinColumns = join.columns\n",
    "y = join.admit\n",
    "X = join[ joinColumns[1:3] + joinColumns[4:] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data randomly into datasets, 70% train, 30% test using test train split\n",
    "# HINT: X_train, X_test, y_train, y_test = train_test_split( parameters )\n",
    "# call them X_train, X_test, y_train, and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit the model using statsmodels.api.sm\n",
    "# HINT: sm.logit(y_train, X_train) then fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add y_test as a new column in X_test, and then make another dataframe called dfTrain\n",
    "# and set it equal to X_test, after X_test has the new y_test column\n",
    "# HINT: X_test[\"actualAdmit\"] = y_test\n",
    "\n",
    "# create a new column in dfTrain that is the predicted admitance value using the result logit model\n",
    "# note you will need a dataframe with only the features (including intercept)\n",
    "# note the dummy column has already been removed\n",
    "\n",
    "# HINT: \n",
    "#dfTrain['predictedAdmit'] = result.predict( dfTrain[ listOfFeatureCols ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a function call scalePredictor, that will take two parameters called \"prob\" and \"threshold\"\n",
    "# the function will check if the probability is greater than or equal to the threshold, \n",
    "# return 1 if true, else return 0\n",
    "\n",
    "# create a while loop, starting at i = 0.30 and ending i <= 0.50, in increments of 0.01. \n",
    "# In this while loop you will create a new predictionAdmit_Threshold column in every iteration\n",
    "# this column will be populated by using scalePredictor each time\n",
    "# after the new column is populated, print out a confusion matrix (use crosstab (within the loop!) )\n",
    "# note the first parameter in crosstab will always be dfTrain['actualAdmit'] while the second\n",
    "# parameter will be the new column in that iteration\n",
    "# interpret each iteration, and decide on the best threshold in each iteration.\n",
    "\n",
    "# HINTS:\n",
    "\n",
    "#i = 0.30\n",
    "#while i <= 0.50:\n",
    "    \n",
    "#    dfTrain[ 'predictedAdmit_{}'.format(i) ] = finish code here\n",
    "    \n",
    "#    print pd.crosstab(\n",
    "#        dfTrain['actualAdmit'],\n",
    "#        put new dfTrain column here, \n",
    "#        rownames=['admit']\n",
    "#    )\n",
    "#    i += 0.01\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
