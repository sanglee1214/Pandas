{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige\n",
      "0      0  380.0  3.61       3.0\n",
      "1      1  660.0  3.67       3.0\n",
      "2      1  800.0  4.00       1.0\n",
      "3      1  640.0  3.19       4.0\n",
      "4      0  520.0  2.93       4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SangYeob/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:20: FutureWarning: using '+' to provide set union with Indexes is deprecated, use '|' or .union()\n"
     ]
    }
   ],
   "source": [
    "# This dataset you have seen, but this time we will properly split the data from the actual\n",
    "# dataset into two, and fit the model on the train dataset, and test on the test dataset.\n",
    "# Then we will iterate through class thresholds, to see which threshold gives the best confusion\n",
    "# matrix. The first steps have been done for you \n",
    "# (creating dummies, joining to df, creating y series and features only dataframe \n",
    "# but please be familiar with these first steps! \n",
    "\n",
    "df_raw = pd.read_csv(\"../../assets/admissions.csv\")\n",
    "df = df_raw.dropna() \n",
    "\n",
    "dummies = pd.get_dummies( df[\"prestige\"], prefix = \"prestige\" )\n",
    "\n",
    "print df.head()\n",
    "\n",
    "join = df[ df.columns[0:3] ].join(dummies)\n",
    "join[\"intercept\"] = 1\n",
    "\n",
    "joinColumns = join.columns\n",
    "y = join.admit\n",
    "X = join[ joinColumns[1:3] + joinColumns[4:] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data randomly into datasets, 70% train, 30% test using test train split\n",
    "# HINT: X_train, X_test, y_train, y_test = train_test_split( parameters )\n",
    "# call them X_train, X_test, y_train, and y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.567931\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>admit</td>      <th>  No. Observations:  </th>  <td>   277</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   271</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 30 Jun 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.09148</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>11:39:28</td>     <th>  Log-Likelihood:    </th> <td> -157.32</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -173.16</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>6.873e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>          <td>    0.9387</td> <td>    0.401</td> <td>    2.342</td> <td> 0.019</td> <td>    0.153     1.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>          <td>    0.0024</td> <td>    0.001</td> <td>    1.805</td> <td> 0.071</td> <td>   -0.000     0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>    <td>   -4.6529</td> <td>    1.349</td> <td>   -3.450</td> <td> 0.001</td> <td>   -7.296    -2.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_2.0</th> <td>   -0.5204</td> <td>    0.379</td> <td>   -1.374</td> <td> 0.169</td> <td>   -1.263     0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_3.0</th> <td>   -1.2389</td> <td>    0.414</td> <td>   -2.996</td> <td> 0.003</td> <td>   -2.050    -0.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_4.0</th> <td>   -1.4674</td> <td>    0.527</td> <td>   -2.782</td> <td> 0.005</td> <td>   -2.501    -0.434</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   No. Observations:                  277\n",
       "Model:                          Logit   Df Residuals:                      271\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Thu, 30 Jun 2016   Pseudo R-squ.:                 0.09148\n",
       "Time:                        11:39:28   Log-Likelihood:                -157.32\n",
       "converged:                       True   LL-Null:                       -173.16\n",
       "                                        LLR p-value:                 6.873e-06\n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------\n",
       "gpa              0.9387      0.401      2.342      0.019         0.153     1.724\n",
       "gre              0.0024      0.001      1.805      0.071        -0.000     0.005\n",
       "intercept       -4.6529      1.349     -3.450      0.001        -7.296    -2.010\n",
       "prestige_2.0    -0.5204      0.379     -1.374      0.169        -1.263     0.222\n",
       "prestige_3.0    -1.2389      0.414     -2.996      0.003        -2.050    -0.428\n",
       "prestige_4.0    -1.4674      0.527     -2.782      0.005        -2.501    -0.434\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model using statsmodels.api.sm\n",
    "# HINT: sm.logit(y_train, X_train) then fit it\n",
    "logReg = sm.Logit(y_train,X_train)\n",
    "result = logReg.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11a258e50>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib\n",
    "\n",
    "#sns.lmplot('gre','admit',join,logistic=True)\n",
    "sns.heatmap(join.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SangYeob/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/SangYeob/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# add y_test as a new column in X_test, and then make another dataframe called dfTrain\n",
    "# and set it equal to X_test, after X_test has the new y_test column\n",
    "# HINT: X_test[\"actualAdmit\"] = y_test\n",
    "X_test[\"actualAdmit\"] = y_test\n",
    "dfTrain = X_test\n",
    "# create a new column in dfTrain that is the predicted admitance value using the result logit model\n",
    "# note you will need a dataframe with only the features (including intercept)\n",
    "# note the dummy column has already been removed\n",
    "# HINT: \n",
    "#dfTrain['predictedAdmit'] = result.predict( dfTrain[ listOfFeatureCols ] )\n",
    "dfTrain['predictedAdmit'] = result.predict(dfTrain.ix[:,:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpa             2.556585\n",
      "gre             1.002400\n",
      "intercept       0.009534\n",
      "prestige_2.0    0.594311\n",
      "prestige_3.0    0.289693\n",
      "prestige_4.0    0.230531\n",
      "dtype: float64\n",
      "                  2.5%     97.5%        OR\n",
      "gpa           1.165402  5.608475  2.556585\n",
      "gre           0.999794  1.005013  1.002400\n",
      "intercept     0.000678  0.134046  0.009534\n",
      "prestige_2.0  0.282924  1.248409  0.594311\n",
      "prestige_3.0  0.128793  0.651608  0.289693\n",
      "prestige_4.0  0.081993  0.648159  0.230531\n"
     ]
    }
   ],
   "source": [
    "print np.exp(result.params)\n",
    "params = result.params\n",
    "conf = result.conf_int()\n",
    "conf['OR'] = params\n",
    "conf.columns = ['2.5%', '97.5%', 'OR']\n",
    "print np.exp(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a function call scalePredictor, that will take two parameters called \"prob\" and \"threshold\"\n",
    "# the function will check if the probability is greater than or equal to the threshold, \n",
    "# return 1 if true, else return 0\n",
    "\n",
    "# create a while loop, starting at i = 0.30 and ending i <= 0.50, in increments of 0.01. \n",
    "# In this while loop you will create a new predictionAdmit_Threshold column in every iteration\n",
    "# this column will be populated by using scalePredictor each time\n",
    "# after the new column is populated, print out a confusion matrix (use crosstab (within the loop!) )\n",
    "# note the first parameter in crosstab will always be dfTrain['actualAdmit'] while the second\n",
    "# parameter will be the new column in that iteration\n",
    "# interpret each iteration, and decide on the best threshold in each iteration.\n",
    "\n",
    "# HINTS:\n",
    "\n",
    "#i = 0.30\n",
    "#while i <= 0.50:\n",
    "    \n",
    "#    dfTrain[ 'predictedAdmit_{}'.format(i) ] = finish code here\n",
    "    \n",
    "#    print pd.crosstab(\n",
    "#        dfTrain['actualAdmit'],\n",
    "#        put new dfTrain column here, \n",
    "#        rownames=['admit']\n",
    "#    )\n",
    "#    i += 0.01\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
