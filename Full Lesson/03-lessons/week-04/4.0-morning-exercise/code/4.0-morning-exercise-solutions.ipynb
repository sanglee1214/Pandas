{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige_1.0  prestige_2.0  prestige_3.0  prestige_4.0  \\\n",
      "0      0  380.0  3.61           0.0           0.0           1.0           0.0   \n",
      "1      1  660.0  3.67           0.0           0.0           1.0           0.0   \n",
      "2      1  800.0  4.00           1.0           0.0           0.0           0.0   \n",
      "3      1  640.0  3.19           0.0           0.0           0.0           1.0   \n",
      "4      0  520.0  2.93           0.0           0.0           0.0           1.0   \n",
      "\n",
      "   intercept  \n",
      "0          1  \n",
      "1          1  \n",
      "2          1  \n",
      "3          1  \n",
      "4          1   (397, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jb3/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:19: FutureWarning: using '+' to provide set union with Indexes is deprecated, use '|' or .union()\n"
     ]
    }
   ],
   "source": [
    "# This dataset you have seen, but this time we will properly split the data from the actual\n",
    "# dataset into two, and fit the model on the train dataset, and test on the test dataset.\n",
    "# Then we will iterate through class thresholds, to see which threshold gives the best confusion\n",
    "# matrix. The first steps have been done for you \n",
    "# (creating dummies, joining to df, creating y series and features only dataframe \n",
    "# but please be familiar with these first steps! \n",
    "\n",
    "df = pd.read_csv(\"../../assets/admissions.csv\").dropna()\n",
    "dummies = pd.get_dummies( df[\"prestige\"], prefix = \"prestige\" )\n",
    "\n",
    "\n",
    "join = df[ df.columns[0:3] ].join(dummies)\n",
    "join[\"intercept\"] = 1\n",
    "\n",
    "print join.head(), join.shape\n",
    "\n",
    "joinColumns = join.columns\n",
    "y = join.admit\n",
    "X = join[ joinColumns[1:3] + joinColumns[4:] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x11d50a810>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib\n",
    "\n",
    "#sns.lmplot('prestige_3.0', 'admit', join, logistic=True)\n",
    "#sns.heatmap(join.corr())\n",
    "join.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data randomly into datasets, 70% train, 30% test using test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.540877\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>admit</td>      <th>  No. Observations:  </th>  <td>   277</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   271</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 30 Jun 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.1002</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>12:35:43</td>     <th>  Log-Likelihood:    </th> <td> -149.82</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -166.50</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>3.202e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>          <td>    1.0557</td> <td>    0.431</td> <td>    2.451</td> <td> 0.014</td> <td>    0.211     1.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>          <td>    0.0031</td> <td>    0.001</td> <td>    2.257</td> <td> 0.024</td> <td>    0.000     0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>    <td>   -5.8192</td> <td>    1.521</td> <td>   -3.827</td> <td> 0.000</td> <td>   -8.800    -2.839</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_2.0</th> <td>   -0.1663</td> <td>    0.397</td> <td>   -0.419</td> <td> 0.675</td> <td>   -0.944     0.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_3.0</th> <td>   -1.1084</td> <td>    0.439</td> <td>   -2.527</td> <td> 0.011</td> <td>   -1.968    -0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_4.0</th> <td>   -1.1220</td> <td>    0.502</td> <td>   -2.234</td> <td> 0.025</td> <td>   -2.106    -0.138</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   No. Observations:                  277\n",
       "Model:                          Logit   Df Residuals:                      271\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Thu, 30 Jun 2016   Pseudo R-squ.:                  0.1002\n",
       "Time:                        12:35:43   Log-Likelihood:                -149.82\n",
       "converged:                       True   LL-Null:                       -166.50\n",
       "                                        LLR p-value:                 3.202e-06\n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------\n",
       "gpa              1.0557      0.431      2.451      0.014         0.211     1.900\n",
       "gre              0.0031      0.001      2.257      0.024         0.000     0.006\n",
       "intercept       -5.8192      1.521     -3.827      0.000        -8.800    -2.839\n",
       "prestige_2.0    -0.1663      0.397     -0.419      0.675        -0.944     0.612\n",
       "prestige_3.0    -1.1084      0.439     -2.527      0.011        -1.968    -0.249\n",
       "prestige_4.0    -1.1220      0.502     -2.234      0.025        -2.106    -0.138\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model using statsmodels.api.sm\n",
    "\n",
    "logit = sm.Logit(y_train, X_train)\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpa             2.873924\n",
      "gre             1.003144\n",
      "intercept       0.002970\n",
      "prestige_2.0    0.846806\n",
      "prestige_3.0    0.330093\n",
      "prestige_4.0    0.325640\n",
      "dtype: float64\n",
      "                  2.5%     97.5%        OR\n",
      "gpa           1.235445  6.685396  2.873924\n",
      "gre           1.000413  1.005882  1.003144\n",
      "intercept     0.000151  0.058510  0.002970\n",
      "prestige_2.0  0.388925  1.843751  0.846806\n",
      "prestige_3.0  0.139742  0.779731  0.330093\n",
      "prestige_4.0  0.121679  0.871484  0.325640\n"
     ]
    }
   ],
   "source": [
    "# odds ratios only\n",
    "print np.exp(result.params)\n",
    "\n",
    "params = result.params\n",
    "conf = result.conf_int()\n",
    "conf['OR'] = params\n",
    "conf.columns = ['2.5%', '97.5%', 'OR']\n",
    "print np.exp(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'gpa', u'gre', u'intercept', u'prestige_2.0', u'prestige_3.0',\n",
      "       u'prestige_4.0', u'actualAdmit'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jb3/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jb3/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# add y_test as a new column in X_test, and then make another dataframe called dfTrain\n",
    "# and set it equal to X_test, after X_test has the new y_test column\n",
    "\n",
    "X_test[\"actualAdmit\"] = y_test\n",
    "X_test.head()\n",
    "dfTrain = X_test\n",
    "\n",
    "print dfTrain.columns\n",
    "\n",
    "# create a new column in dfTrain that is the predicted admitance value using the result logit model\n",
    "# note you will need a dataframe with only the features (including intercept)\n",
    "# note the dummy column has already been removed\n",
    "\n",
    "dfTrain['predictedAdmit'] = result.predict( dfTrain[ dfTrain.columns[0:6] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jb3/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictedAdmit_0.3   0   1\n",
      "admit                     \n",
      "0                   39  35\n",
      "1                   17  29\n",
      "predictedAdmit_0.31   0   1\n",
      "admit                      \n",
      "0                    42  32\n",
      "1                    18  28\n",
      "predictedAdmit_0.32   0   1\n",
      "admit                      \n",
      "0                    44  30\n",
      "1                    19  27\n",
      "predictedAdmit_0.33   0   1\n",
      "admit                      \n",
      "0                    44  30\n",
      "1                    20  26\n",
      "predictedAdmit_0.34   0   1\n",
      "admit                      \n",
      "0                    46  28\n",
      "1                    21  25\n",
      "predictedAdmit_0.35   0   1\n",
      "admit                      \n",
      "0                    48  26\n",
      "1                    21  25\n",
      "predictedAdmit_0.36   0   1\n",
      "admit                      \n",
      "0                    52  22\n",
      "1                    21  25\n",
      "predictedAdmit_0.37   0   1\n",
      "admit                      \n",
      "0                    54  20\n",
      "1                    23  23\n",
      "predictedAdmit_0.38   0   1\n",
      "admit                      \n",
      "0                    56  18\n",
      "1                    24  22\n",
      "predictedAdmit_0.39   0   1\n",
      "admit                      \n",
      "0                    56  18\n",
      "1                    25  21\n",
      "predictedAdmit_0.4   0   1\n",
      "admit                     \n",
      "0                   59  15\n",
      "1                   27  19\n",
      "predictedAdmit_0.41   0   1\n",
      "admit                      \n",
      "0                    60  14\n",
      "1                    29  17\n",
      "predictedAdmit_0.42   0   1\n",
      "admit                      \n",
      "0                    60  14\n",
      "1                    29  17\n",
      "predictedAdmit_0.43   0   1\n",
      "admit                      \n",
      "0                    60  14\n",
      "1                    31  15\n",
      "predictedAdmit_0.44   0   1\n",
      "admit                      \n",
      "0                    61  13\n",
      "1                    31  15\n",
      "predictedAdmit_0.45   0   1\n",
      "admit                      \n",
      "0                    62  12\n",
      "1                    32  14\n",
      "predictedAdmit_0.46   0   1\n",
      "admit                      \n",
      "0                    62  12\n",
      "1                    34  12\n",
      "predictedAdmit_0.47   0   1\n",
      "admit                      \n",
      "0                    62  12\n",
      "1                    35  11\n",
      "predictedAdmit_0.48   0   1\n",
      "admit                      \n",
      "0                    62  12\n",
      "1                    36  10\n",
      "predictedAdmit_0.49   0   1\n",
      "admit                      \n",
      "0                    63  11\n",
      "1                    36  10\n"
     ]
    }
   ],
   "source": [
    "# create a function call scale predictor, that will take two parameters called \"prob\" and \"threshold\"\n",
    "# the function will check if the probability is greater than or equal to the threshold, \n",
    "# return 1, else return 0\n",
    "\n",
    "def scalePredictor(prob, threshold):\n",
    "    if( prob >= threshold ):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# create a while loop, starting at i = 0.30 and ending i <= 0.50, in increments of 0.01. \n",
    "# In this while loop you will create a new predictionAdmit_Threshold column in every iteration\n",
    "# this column will be populated by using scalePredictor each time\n",
    "# after the new column is populated, print out a confusion matrix (use crosstab (within the loop!) )\n",
    "# note the first parameter in crosstab will always be dfTrain['actualAdmit'] while the second\n",
    "# parameter will be the new column in that iteration\n",
    "# interpret each iteration, and decide on the best threshold in each iteration.\n",
    "\n",
    "i = 0.30\n",
    "while i <= 0.50:\n",
    "    \n",
    "    dfTrain[ 'predictedAdmit_{}'.format(i) ] = dfTrain.predictedAdmit.apply(\n",
    "        lambda prob: scalePredictor(prob,i) )\n",
    "    \n",
    "    print pd.crosstab(\n",
    "        dfTrain['actualAdmit'],\n",
    "        dfTrain['predictedAdmit_{}'.format(i)], \n",
    "        rownames=['admit']\n",
    "    )\n",
    "    i += 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
